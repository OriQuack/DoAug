{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf308dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q torch==2.5.1 transformers==4.45.2 datasets sentence-transformers peft accelerate trl==0.11.4 scikit-learn tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dohyun/.conda/envs/doaug/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Artifacts will be saved to: doaug_artifacts_v2\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch, os, json, random, ast\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorWithPadding,\n",
    "    pipeline,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from trl import DPOTrainer, DPOConfig, SFTTrainer, SFTConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, Optional, List\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BASE_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "WORKDIR = Path(\"./doaug_artifacts\")\n",
    "WORKDIR.mkdir(exist_ok=True)\n",
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"Hugging Face Hub 토큰을 'HF_TOKEN' 환경 변수로 설정해주세요.\")\n",
    "\n",
    "SYSTEM_MESSAGE = \"You are a helpful assistant that only paraphrases.\"\n",
    "\n",
    "print(f\"Using {DEVICE}\")\n",
    "print(f\"Artifacts will be saved to: {WORKDIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e81279",
   "metadata": {},
   "source": [
    "# 1️⃣ Supervised Fine‑Tuning (SFT)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51fd76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. SFT Stage ---\n",
      "DSFT_100k.jsonl already exists at doaug_artifacts_v2/DSFT_100k.jsonl. Skipping generation.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 1. SFT Stage ---\")\n",
    "\n",
    "dsft_path = WORKDIR / \"DSFT_100k.jsonl\"\n",
    "raw_all = load_dataset(\"humarin/chatgpt-paraphrases\", split=\"train\")\n",
    "\n",
    "if dsft_path.exists():\n",
    "    print(f\"DSFT_100k.jsonl already exists at {dsft_path}. Skipping generation.\")\n",
    "else:\n",
    "    print(\"(i) Building DSFT_100k dataset...\")\n",
    "\n",
    "    rng = random.Random(321)\n",
    "    shuffled_ds = raw_all.shuffle(seed=123)\n",
    "    pairs = []\n",
    "    dsft_sources = set()\n",
    "    pbar = tqdm(total=100_000, desc=\"Generating 100k SFT pairs\")\n",
    "    for ex in shuffled_ds:\n",
    "        if len(pairs) >= 100_000:\n",
    "            break\n",
    "        orig = ex[\"text\"]\n",
    "        if orig in dsft_sources:\n",
    "            continue\n",
    "        dsft_sources.add(orig)\n",
    "        pars = ex[\"paraphrases\"]\n",
    "        if isinstance(pars, str):\n",
    "            try:\n",
    "                pars = ast.literal_eval(pars)\n",
    "            except (ValueError, SyntaxError):\n",
    "                continue\n",
    "        for para in pars:\n",
    "            if len(pairs) >= 100_000:\n",
    "                break\n",
    "            pairs.append({\"sentence\": orig, \"paraphrase\": para})\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    assert len(pairs) == 100_000\n",
    "\n",
    "    with open(dsft_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p in pairs:\n",
    "            f.write(json.dumps(p, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"DSFT saved to {dsft_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184dd218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ii) Tokenizing dataset for SFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100000/100000 [00:40<00:00, 2441.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized SFT dataset created. 0 examples were filtered out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"(ii) Tokenizing dataset for SFT...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True, token=HF_TOKEN)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "def format_and_mask_chat(example: Dict) -> Optional[Dict]:\n",
    "    # ... (이전과 동일한 안정적인 마스킹 로직) ...\n",
    "    chat_with_assistant = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"You will be given a sentence. Please paraphrase the sentence.\\nSentence: {example['sentence']}\",\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": example[\"paraphrase\"]},\n",
    "    ]\n",
    "    chat_prompt_only = chat_with_assistant[:-1]\n",
    "    prompt_ids = tokenizer.apply_chat_template(\n",
    "        chat_prompt_only, tokenize=True, add_generation_prompt=True\n",
    "    )\n",
    "    full_ids = tokenizer.apply_chat_template(\n",
    "        chat_with_assistant, tokenize=True, add_generation_prompt=False\n",
    "    )\n",
    "    maxlen = tokenizer.model_max_length\n",
    "    if len(prompt_ids) >= maxlen:\n",
    "        return None\n",
    "    labels = full_ids.copy()\n",
    "    labels[: len(prompt_ids)] = [-100] * len(prompt_ids)\n",
    "    input_ids = full_ids[:maxlen]\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    labels = labels[:maxlen]\n",
    "    if all(l == -100 for l in labels):\n",
    "        return None\n",
    "    if len(labels) < len(input_ids):\n",
    "        labels += [-100] * (len(input_ids) - len(labels))\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "\n",
    "dsft = load_dataset(\"json\", data_files=str(dsft_path))[\"train\"]\n",
    "tokenized_dsft = dsft.map(format_and_mask_chat, remove_columns=dsft.column_names)\n",
    "print(\n",
    "    f\"Tokenized SFT dataset created. {len(dsft) - len(tokenized_dsft)} examples were filtered out.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d03853",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(iii) Preparing model and training SFT LoRA adapter...\")\n",
    "\n",
    "\n",
    "class ChatDataCollator:\n",
    "    def __init__(self, tokenizer, padding=\"longest\"):\n",
    "        self.pad = DataCollatorWithPadding(tokenizer, padding=padding)\n",
    "\n",
    "    def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        labels = [f.pop(\"labels\") for f in features]\n",
    "\n",
    "        batch = self.pad(features)\n",
    "\n",
    "        max_len = batch[\"input_ids\"].size(1)\n",
    "        padded = [l + [-100] * (max_len - len(l)) for l in labels]\n",
    "        batch[\"labels\"] = torch.tensor(padded, dtype=torch.long)\n",
    "        return batch\n",
    "\n",
    "\n",
    "collator = ChatDataCollator(tokenizer, padding=\"longest\")\n",
    "\n",
    "# 논문 명세: Llama-3.2-1B-Instruct with BF16 (부록 C)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL, torch_dtype=torch.bfloat16, device_map=\"auto\", token=HF_TOKEN\n",
    ")\n",
    "# 논문 명세: LoRA rank r = 8 (부록 C)\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.config.use_cache = False\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 논문 부록 C의 SFT 단계 하이퍼파라미터 설정\n",
    "sft_cfg = SFTConfig(\n",
    "    output_dir=str(WORKDIR / \"sft\"),\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=100,\n",
    "    bf16=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    max_seq_length=tokenizer.model_max_length,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=tokenized_dsft,\n",
    "    args=sft_cfg,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    ")\n",
    "trainer.train(resume_from_checkpoint=get_last_checkpoint(sft_cfg.output_dir))\n",
    "print(\"SFT training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7239ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iv) Merging SFT LoRA adapter and saving the final model...\n",
      "SFT-merged model saved to: doaug_artifacts_v2/sft_merged\n"
     ]
    }
   ],
   "source": [
    "print(\"(iv) Merging SFT LoRA adapter and saving the final model...\")\n",
    "del trainer, model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL, torch_dtype=torch.bfloat16, device_map=\"auto\", token=HF_TOKEN\n",
    ")\n",
    "ckpts = sorted(\n",
    "    Path(sft_cfg.output_dir).glob(\"checkpoint-*\"),\n",
    "    key=lambda x: int(x.name.split(\"-\")[-1]),\n",
    ")\n",
    "if not ckpts:\n",
    "    raise ValueError(\"No SFT checkpoint found.\")\n",
    "last_checkpoint_path = ckpts[-1]\n",
    "\n",
    "sft_model = PeftModel.from_pretrained(base_model, str(last_checkpoint_path))\n",
    "sft_model = sft_model.merge_and_unload()\n",
    "\n",
    "sft_merged_dir = WORKDIR / \"sft_merged\"\n",
    "sft_model.save_pretrained(sft_merged_dir)\n",
    "tokenizer.save_pretrained(sft_merged_dir)\n",
    "print(f\"SFT-merged model saved to: {sft_merged_dir}\")\n",
    "del base_model, sft_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bff6fe",
   "metadata": {},
   "source": [
    "# 2️⃣ Direct Preference Optimization (DPO)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3dcc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. DPO Stage ---\n",
      "DDPO_50k already exists at doaug_artifacts_v2/DDPO_50k.jsonl. Skipping generation.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 2. DPO Stage ---\")\n",
    "ddpo_path = WORKDIR / \"DDPO_50k.jsonl\"\n",
    "\n",
    "if ddpo_path.exists():\n",
    "    print(f\"DDPO_50k already exists at {ddpo_path}. Skipping generation.\")\n",
    "else:\n",
    "    print(\"(i) Building DDPO_50k dataset...\")\n",
    "    EMB_MODEL = \"sentence-transformers/all-MPNet-base-v2\"\n",
    "    embedder = SentenceTransformer(EMB_MODEL, device=DEVICE)\n",
    "    raw_ddpo_candidates = [ex for ex in raw_all if ex[\"text\"] not in dsft_sources]\n",
    "    raw_ddpo = rng.sample(raw_ddpo_candidates, 50_000)\n",
    "\n",
    "    prefs = []\n",
    "    BATCH = 64\n",
    "    for i in tqdm(range(0, len(raw_ddpo), BATCH), desc=\"Building DPO dataset\"):\n",
    "        chunk = raw_ddpo[i : i + BATCH]\n",
    "        sentences = [ex[\"text\"] for ex in chunk]\n",
    "        paraphrase_lists = [\n",
    "            (\n",
    "                ast.literal_eval(ex[\"paraphrases\"])\n",
    "                if isinstance(ex[\"paraphrases\"], str)\n",
    "                else ex[\"paraphrases\"]\n",
    "            )\n",
    "            for ex in chunk\n",
    "        ]\n",
    "        flat, valid_indices = [], []\n",
    "        for j, (src, plist) in enumerate(zip(sentences, paraphrase_lists)):\n",
    "            if isinstance(plist, list) and len(plist) >= 2:\n",
    "                flat.append(src)\n",
    "                flat.extend(plist)\n",
    "                valid_indices.append(j)\n",
    "        if not flat:\n",
    "            continue\n",
    "        embs = F.normalize(\n",
    "            embedder.encode(flat, convert_to_tensor=True, device=DEVICE), p=2, dim=1\n",
    "        )\n",
    "        idx = 0\n",
    "        for j in valid_indices:\n",
    "            src, plist = sentences[j], paraphrase_lists[j]\n",
    "            src_emb = embs[idx]\n",
    "            par_embs = embs[idx + 1 : idx + 1 + len(plist)]\n",
    "            idx += 1 + len(plist)\n",
    "            dists = 1 - (par_embs @ src_emb)\n",
    "            if dists.numel() < 2:\n",
    "                continue\n",
    "            iw, il = dists.argmax().item(), dists.argmin().item()\n",
    "            if iw == il:\n",
    "                continue\n",
    "            chosen, rejected = plist[iw], plist[il]\n",
    "            prompt_chat = [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"You will be given a sentence. Please paraphrase the sentence.\\nSentence: {src}\",\n",
    "                },\n",
    "            ]\n",
    "            prompt_str = tokenizer.apply_chat_template(\n",
    "                prompt_chat, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "            prefs.append({\"prompt\": prompt_str, \"chosen\": chosen, \"rejected\": rejected})\n",
    "\n",
    "    with ddpo_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for p in prefs:\n",
    "            f.write(json.dumps(p, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"DPO dataset saved. Size: {len(prefs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f85068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ii) Preparing model for DPO training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"(ii) Preparing model for DPO training...\")\n",
    "sft_dir = WORKDIR / \"sft_merged\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    sft_dir,\n",
    "    use_fast=True,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    sft_dir, torch_dtype=torch.bfloat16, device_map=\"auto\", token=HF_TOKEN\n",
    ")\n",
    "lora_cfg_dpo = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg_dpo)\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(\n",
    "    sft_dir, torch_dtype=torch.bfloat16, device_map=\"auto\", token=HF_TOKEN\n",
    ")\n",
    "ref_model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c536c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iii) Starting DPO training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dohyun/.conda/envs/doaug/lib/python3.9/site-packages/trl/trainer/dpo_trainer.py:708: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "Tokenizing train dataset: 100%|██████████| 50000/50000 [00:36<00:00, 1388.28 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4686' max='4686' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4686/4686 1:50:24, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.692500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.651400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.568200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.303400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.280300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.251100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.269400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.263800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.265500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.239200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.243200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.258200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.244300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.249600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.258300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.254700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.261500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.230200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.263300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.257400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO training finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"(iii) Starting DPO training...\")\n",
    "ddpo_dataset = load_dataset(\"json\", data_files=str(ddpo_path))[\"train\"]\n",
    "\n",
    "dpo_config = DPOConfig(\n",
    "    output_dir=str(WORKDIR / \"dpo\"),\n",
    "    max_length=256,\n",
    "    max_prompt_length=128,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=5e-6,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=100,\n",
    "    bf16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    beta=0.1,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    args=dpo_config,\n",
    "    train_dataset=ddpo_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "dpo_trainer.train(resume_from_checkpoint=get_last_checkpoint(dpo_config.output_dir))\n",
    "print(\"DPO training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769eb1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iv) Merging DPO adapter and saving the final model...\n",
      "DPO-finished model saved to doaug_artifacts_v2/doaug_paraphraser\n"
     ]
    }
   ],
   "source": [
    "print(\"(iv) Merging DPO adapter and saving the final model...\")\n",
    "del dpo_trainer, model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "final_model_peft = PeftModel.from_pretrained(\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        sft_dir, torch_dtype=torch.bfloat16, device_map=\"auto\", token=HF_TOKEN\n",
    "    ),\n",
    "    get_last_checkpoint(dpo_config.output_dir),\n",
    ")\n",
    "final_model = final_model_peft.merge_and_unload()\n",
    "final_dir = WORKDIR / \"doaug_paraphraser\"\n",
    "final_model.save_pretrained(final_dir)\n",
    "tokenizer.save_pretrained(final_dir)\n",
    "print(f\"DPO-finished model saved to {final_dir}\")\n",
    "del final_model, final_model_peft\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007df01",
   "metadata": {},
   "source": [
    "# 3️⃣ Quick Inference Check\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6edfbc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Inference Check ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 3. Inference Check ---\")\n",
    "paraphraser = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=str(final_dir),\n",
    "    tokenizer=tokenizer,\n",
    "    device=0,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "def paraphrase(sentence: str):\n",
    "    prompt_chat = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"You will be given a sentence. Please paraphrase the sentence.\\nSentence: {sentence}\",\n",
    "        },\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        prompt_chat, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    generated_text = paraphraser(\n",
    "        prompt,\n",
    "        max_new_tokens=64,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )[0][\"generated_text\"]\n",
    "    response_part = (\n",
    "        generated_text.split(prompt, 1)[-1].split(tokenizer.eos_token, 1)[0].strip()\n",
    "    )\n",
    "    return response_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82040a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Paraphrasing:\n",
      "Original: A single candle lit the dark, quiet room.\n",
      "Paraphrased: The ambiance was illuminated by a solitary source of illumination.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest Paraphrasing:\")\n",
    "test_sentence = \"A single candle lit the dark, quiet room.\"\n",
    "print(f\"Original: {test_sentence}\")\n",
    "paraphrased_text = paraphrase(test_sentence)\n",
    "print(f\"Paraphrased: {paraphrased_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doaug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
